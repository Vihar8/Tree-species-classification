# -*- coding: utf-8 -*-
"""Tree_Species_Classification.ipynb

Automatically generated by Colab.

Original file is located at
        https://colab.research.google.com/drive/1IHoiw2TW4nR3SwGzssdG6Do3zwwhL3Tc
"""


import os
import cv2
import numpy as np
import random
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.metrics import TopKCategoricalAccuracy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import shutil
import json
import pickle
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

"""# 1. DATASET EXPLORATION

"""

def explore_dataset(data_dir):
    """
    Explore and analyze the dataset structure and statistics

    Args:
        data_dir (str): Path to the dataset directory

    Returns:
        dict: Dataset statistics and information
    """
    try:
        print("=" * 60)
        print("DATASET EXPLORATION")
        print("=" * 60)

        if not os.path.exists(data_dir):
            raise FileNotFoundError(f"Dataset directory not found: {data_dir}")

        # Get class folders
        class_folders = [d for d in os.listdir(data_dir)
                        if os.path.isdir(os.path.join(data_dir, d)) and not d.startswith('.')]

        if not class_folders:
            raise ValueError("No class folders found in dataset directory")

        print(f"Found {len(class_folders)} classes:")
        print(class_folders)

        # Count images per class
        class_counts = {}
        image_paths = {}

        for class_name in class_folders:
            class_path = os.path.join(data_dir, class_name)
            image_files = [f for f in os.listdir(class_path)
                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

            class_counts[class_name] = len(image_files)
            image_paths[class_name] = [os.path.join(class_path, f) for f in image_files]

        # Display statistics
        print(f"\nImages per class:")
        for cls, count in sorted(class_counts.items()):
            print(f"{cls:20s} : {count}")

        total_images = sum(class_counts.values())
        print(f"\nTotal images: {total_images}")
        print(f"Total classes: {len(class_counts)}")

        # Analyze image dimensions
        print("\nAnalyzing image dimensions...")
        image_shapes = []

        for cls, paths in image_paths.items():
            for img_path in paths[:5]:  # Sample 5 images per class
                try:
                    img = cv2.imread(img_path)
                    if img is not None:
                        h, w, c = img.shape
                        image_shapes.append((h, w, c))
                except Exception as e:
                    print(f"Error reading {img_path}: {e}")

        if image_shapes:
            shape_array = np.array(image_shapes)
            print(f"Image shape statistics (from {len(image_shapes)} samples):")
            print(f"Min Height x Width : {shape_array[:,0].min()} x {shape_array[:,1].min()}")
            print(f"Max Height x Width : {shape_array[:,0].max()} x {shape_array[:,1].max()}")
            print(f"Mean Height x Width: {shape_array[:,0].mean():.1f} x {shape_array[:,1].mean():.1f}")
            print(f"Channels: {np.unique(shape_array[:,2])}")

        dataset_info = {
            'classes': class_folders,
            'class_counts': class_counts,
            'total_images': total_images,
            'num_classes': len(class_folders),
            'image_paths': image_paths
        }

        return dataset_info

    except Exception as e:
        print(f"Error in dataset exploration: {e}")
        raise

def visualize_dataset_samples(dataset_info, data_dir, samples_per_row=5, max_classes=15):
    """
    Visualize sample images from each class

    Args:
        dataset_info (dict): Dataset information from explore_dataset
        data_dir (str): Path to dataset directory
        samples_per_row (int): Number of samples per row
        max_classes (int): Maximum classes to display
    """
    try:
        print("\nVisualizing dataset samples...")

        classes = sorted(dataset_info['classes'])[:max_classes]
        rows = (len(classes) + samples_per_row - 1) // samples_per_row

        plt.figure(figsize=(16, 4 * rows))

        for i, cls in enumerate(classes):
            cls_path = os.path.join(data_dir, cls)
            image_files = [f for f in os.listdir(cls_path)
                          if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

            if image_files:
                img_path = os.path.join(cls_path, image_files[0])
                img = cv2.imread(img_path)
                if img is not None:
                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                    plt.subplot(rows, samples_per_row, i + 1)
                    plt.imshow(img)
                    plt.title(f"{cls}\n({dataset_info['class_counts'][cls]} images)")
                    plt.axis('off')

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"Error in visualization: {e}")

"""# 2. DATA PREPROCESSING"""

def create_data_splits(dataset_info, output_dir, test_size=0.2, val_size=0.2, random_state=42):
    """
    Split dataset into train, validation, and test sets

    Args:
        dataset_info (dict): Dataset information
        output_dir (str): Output directory for processed data
        test_size (float): Proportion of test data
        val_size (float): Proportion of validation data from remaining data
        random_state (int): Random state for reproducibility

    Returns:
        dict: Information about created splits
    """
    try:
        print("=" * 60)
        print("DATA PREPROCESSING - CREATING SPLITS")
        print("=" * 60)

        # Clean up existing directory
        if os.path.exists(output_dir):
            print(f"Removing existing directory: {output_dir}")
            shutil.rmtree(output_dir)

        # Create directories
        train_dir = os.path.join(output_dir, 'train')
        val_dir = os.path.join(output_dir, 'validation')
        test_dir = os.path.join(output_dir, 'test')

        for dir_path in [train_dir, val_dir, test_dir]:
            os.makedirs(dir_path, exist_ok=True)

        split_info = {
            'train': {'total': 0, 'per_class': {}},
            'val': {'total': 0, 'per_class': {}},
            'test': {'total': 0, 'per_class': {}}
        }

        # Split each class
        for cls, image_paths in dataset_info['image_paths'].items():
            if len(image_paths) < 3:  # Skip classes with too few images
                print(f"Warning: Skipping class '{cls}' - only {len(image_paths)} images")
                continue

            # New split logic: 80% train, 10% val, 10% test
            train_ratio = 0.8
            val_ratio = 0.1
            test_ratio = 0.1

            # Shuffle before splitting
            random.seed(random_state)
            random.shuffle(image_paths)

            total = len(image_paths)
            train_end = int(train_ratio * total)
            val_end = train_end + int(val_ratio * total)

            train_paths = image_paths[:train_end]
            val_paths = image_paths[train_end:val_end]
            test_paths = image_paths[val_end:]

            # Create class directories
            for split_dir in [train_dir, val_dir, test_dir]:
                os.makedirs(os.path.join(split_dir, cls), exist_ok=True)

            # Copy files
            for split_name, paths, target_dir in [
                ('train', train_paths, train_dir),
                ('val', val_paths, val_dir),
                ('test', test_paths, test_dir)
            ]:
                for img_path in paths:
                    target_path = os.path.join(target_dir, cls, os.path.basename(img_path))
                    shutil.copy2(img_path, target_path)

                split_info[split_name]['per_class'][cls] = len(paths)
                split_info[split_name]['total'] += len(paths)

            print(f"Split {cls}: {len(train_paths)} train, {len(val_paths)} val, {len(test_paths)} test")

        # Save split information
        split_info_path = os.path.join(output_dir, 'split_info.json')
        with open(split_info_path, 'w') as f:
            json.dump(split_info, f, indent=2)

        print(f"\nSplit Summary:")
        print(f"Training: {split_info['train']['total']} images")
        print(f"Validation: {split_info['val']['total']} images")
        print(f"Test: {split_info['test']['total']} images")

        return {
            'train_dir': train_dir,
            'val_dir': val_dir,
            'test_dir': test_dir,
            'split_info': split_info
        }

    except Exception as e:
        print(f"Error in creating data splits: {e}")
        raise

def create_data_generators(train_dir, val_dir, img_height=224, img_width=224, batch_size=32):
    """
    Create data generators with augmentation

    Args:
        train_dir (str): Training data directory
        val_dir (str): Validation data directory
        img_height (int): Target image height
        img_width (int): Target image width
        batch_size (int): Batch size

    Returns:
        tuple: (train_generator, val_generator, class_names)
    """
    try:
        print("\nCreating data generators with augmentation...")

        # Enhanced data augmentation for training
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=20,
            width_shift_range=0.1,
            height_shift_range=0.1,
            shear_range=0.1,
            zoom_range=0.1,
            horizontal_flip=True,
            vertical_flip=False,
            brightness_range=[0.9, 1.1],  # Reduced from [0.8, 1.2]
            fill_mode='nearest'
        )

        # Only rescaling for validation
        val_datagen = ImageDataGenerator(rescale=1./255)

        # Create generators
        train_generator = train_datagen.flow_from_directory(
            train_dir,
            target_size=(img_height, img_width),
            batch_size=batch_size,
            class_mode='categorical',
            shuffle=True
        )

        val_generator = val_datagen.flow_from_directory(
            val_dir,
            target_size=(img_height, img_width),
            batch_size=batch_size,
            class_mode='categorical',
            shuffle=False
        )

        print(f"Training generator: {train_generator.samples} images, {train_generator.num_classes} classes")
        print(f"Validation generator: {val_generator.samples} images, {val_generator.num_classes} classes")

        # Get class names
        class_names = list(train_generator.class_indices.keys())

        return train_generator, val_generator, class_names

    except Exception as e:
        print(f"Error creating data generators: {e}")
        raise

def calculate_class_weights(train_generator):
    """Calculate class weights for imbalanced dataset"""
    from sklearn.utils.class_weight import compute_class_weight

    # Get all labels
    labels = []
    for i in range(len(train_generator)):
        _, batch_labels = train_generator[i]
        labels.extend(np.argmax(batch_labels, axis=1))

    # Calculate class weights
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(labels),
        y=labels
    )

    return dict(enumerate(class_weights))

"""# 3. MODEL BUILDING"""

def create_model(num_classes, img_height=224, img_width=224, dropout_rate=0.5):
    """
    Create an improved model using EfficientNetB0 with additional layers

    Args:
        num_classes (int): Number of classes
        img_height (int): Input image height
        img_width (int): Input image width
        dropout_rate (float): Dropout rate

    Returns:
        tf.keras.Model: Compiled model
    """
    try:
        print("=" * 60)
        print("MODEL BUILDING")
        print("=" * 60)

        # Load pre-trained EfficientNetB0
        base_model = EfficientNetB0(
            input_shape=(img_height, img_width, 3),
            include_top=False,
            weights='imagenet'
        )

        # Freeze base model initially
        base_model.trainable = False

        # Add custom layers
        model = Sequential([
            base_model,
            GlobalAveragePooling2D(),
            BatchNormalization(),
            Dense(128, activation='relu', kernel_regularizer=l2(0.001)),
            Dropout(dropout_rate),
            Dense(64, activation='relu', kernel_regularizer=l2(0.001)),
            Dropout(dropout_rate * 0.5),
            Dense(num_classes, activation='softmax')
        ])

        # Compile model
        model.compile(
            optimizer=Adam(learning_rate=0.001),  # Lower initial LR
            loss='categorical_crossentropy',
            metrics=['accuracy', 'top_k_categorical_accuracy']
        )

        print("Model created successfully!")
        print(f"Total parameters: {model.count_params():,}")
        print(f"Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}")


        return model

    except Exception as e:
        print(f"Error creating model: {e}")
        raise

def setup_callbacks(model_save_path, patience=5):
    """
    Setup training callbacks

    Args:
        model_save_path (str): Path to save the best model
        patience (int): Patience for early stopping

    Returns:
        list: List of callbacks
    """
    try:
        print("Setting up training callbacks...")

        callbacks = [
            EarlyStopping(
                monitor='val_loss',
                patience=10,  # Increase patience
                restore_best_weights=True,
                verbose=1
            ),
            ModelCheckpoint(
                filepath=model_save_path.replace('.h5', '.keras'),
                monitor='val_accuracy',
                save_best_only=True,
                mode='max',
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.2,
                patience=3,
                min_lr=1e-7,
                verbose=1
            )
        ]

        return callbacks

    except Exception as e:
        print(f"Error setting up callbacks: {e}")
        raise

"""# 4. MODEL TRAINING"""

def train_model(model, train_generator, val_generator, callbacks, epochs=100):
   """
   Train the model with two-stage training (frozen -> unfrozen)

   Args:
       model: Keras model
       train_generator: Training data generator
       val_generator: Validation data generator
       callbacks: Training callbacks
       epochs (int): Number of epochs

   Returns:
       dict: Training history
   """
   try:
       print("=" * 60)
       print("MODEL TRAINING")
       print("=" * 60)

       # Add this line after the function starts
       class_weights = calculate_class_weights(train_generator)

       # Stage 1: Train with frozen base model
       print("Stage 1: Training with frozen base model...")

       history1 = model.fit(
           train_generator,
           steps_per_epoch=train_generator.samples // train_generator.batch_size,
           epochs=epochs // 2,
           validation_data=val_generator,
           validation_steps=val_generator.samples // val_generator.batch_size,
           callbacks=callbacks,
           class_weight=class_weights,  # Add this line
           verbose=1
       )

       # Stage 2: Fine-tune with unfrozen layers
       print("\nStage 2: Fine-tuning with unfrozen layers...")

       # Unfreeze the base model
       model.layers[0].trainable = True

       # Use a lower learning rate for fine-tuning
       model.compile(
           optimizer=Adam(learning_rate=0.0001),
           loss='categorical_crossentropy',
           metrics=['accuracy', 'top_k_categorical_accuracy']
       )

       history2 = model.fit(
           train_generator,
           steps_per_epoch=train_generator.samples // train_generator.batch_size,
           epochs=epochs // 2,
           validation_data=val_generator,
           validation_steps=val_generator.samples // val_generator.batch_size,
           callbacks=callbacks,
           class_weight=class_weights,  # Add this line
           verbose=1
       )

       # Combine histories
       combined_history = {}
       for key in history1.history.keys():
           combined_history[key] = history1.history[key] + history2.history[key]

       print("Model training completed!")

       return {'history': combined_history}

   except Exception as e:
       print(f"Error during training: {e}")
       raise

def plot_training_history(history):
    """
    Plot training history

    Args:
        history (dict): Training history
    """
    try:
        print("Plotting training history...")

        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # Accuracy
        axes[0, 0].plot(history['accuracy'], label='Training Accuracy')
        axes[0, 0].plot(history['val_accuracy'], label='Validation Accuracy')
        axes[0, 0].set_title('Model Accuracy')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Accuracy')
        axes[0, 0].legend()
        axes[0, 0].grid(True)

        # Loss
        axes[0, 1].plot(history['loss'], label='Training Loss')
        axes[0, 1].plot(history['val_loss'], label='Validation Loss')
        axes[0, 1].set_title('Model Loss')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Loss')
        axes[0, 1].legend()
        axes[0, 1].grid(True)

        # Top-3 Accuracy
        axes[1, 0].plot(history['top_k_categorical_accuracy'], label='Training Top-3 Accuracy')
        axes[1, 0].plot(history['val_top_k_categorical_accuracy'], label='Validation Top-3 Accuracy')
        axes[1, 0].set_title('Model Top-3 Accuracy')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Top-3 Accuracy')
        axes[1, 0].legend()
        axes[1, 0].grid(True)

        # Learning rate (if available)
        if 'lr' in history:
            axes[1, 1].plot(history['lr'], label='Learning Rate')
            axes[1, 1].set_title('Learning Rate')
            axes[1, 1].set_xlabel('Epoch')
            axes[1, 1].set_ylabel('Learning Rate')
            axes[1, 1].set_yscale('log')
            axes[1, 1].legend()
            axes[1, 1].grid(True)
        else:
            axes[1, 1].axis('off')

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"Error plotting training history: {e}")

"""# 5. MODEL EVALUATION"""

def evaluate_model(model_path, test_dir, class_names, img_height=224, img_width=224, batch_size=32):
    """
    Evaluate the trained model on test data

    Args:
        model_path (str): Path to saved model
        test_dir (str): Test data directory
        class_names (list): List of class names
        img_height (int): Image height
        img_width (int): Image width
        batch_size (int): Batch size

    Returns:
        dict: Evaluation results
    """
    try:
        print("=" * 60)
        print("MODEL EVALUATION")
        print("=" * 60)

        # Load model
        print(f"Loading model from: {model_path}")
        model = tf.keras.models.load_model(model_path)

        # Create test generator
        test_datagen = ImageDataGenerator(rescale=1./255)
        test_generator = test_datagen.flow_from_directory(
            test_dir,
            target_size=(img_height, img_width),
            batch_size=batch_size,
            class_mode='categorical',
            shuffle=False
        )

        print(f"Test generator: {test_generator.samples} images")

        # Evaluate model
        print("Evaluating model...")
        test_loss, test_accuracy, test_top3_accuracy = model.evaluate(
            test_generator,
            steps=test_generator.samples // batch_size,
            verbose=1
        )

        print(f"\nTest Results:")
        print(f"Test Loss: {test_loss:.4f}")
        print(f"Test Accuracy: {test_accuracy:.4f}")
        print(f"Test Top-3 Accuracy: {test_top3_accuracy:.4f}")

        # Get predictions for detailed analysis
        predictions = model.predict(
            test_generator,
            steps=test_generator.samples // batch_size,
            verbose=1
        )

        # Get true labels
        y_true = test_generator.classes[:len(predictions)]
        y_pred = np.argmax(predictions, axis=1)

        # Classification report
        print("\nClassification Report:")
        report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
        print(classification_report(y_true, y_pred, target_names=class_names))

        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred)

        # Plot confusion matrix
        plt.figure(figsize=(15, 12))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=class_names, yticklabels=class_names)
        plt.title('Confusion Matrix')
        plt.xlabel('Predicted')
        plt.ylabel('Actual')
        plt.xticks(rotation=45, ha='right')
        plt.yticks(rotation=0)
        plt.tight_layout()
        plt.show()

        return {
            'test_loss': test_loss,
            'test_accuracy': test_accuracy,
            'test_top3_accuracy': test_top3_accuracy,
            'classification_report': report,
            'confusion_matrix': cm,
            'predictions': predictions,
            'y_true': y_true,
            'y_pred': y_pred
        }

    except Exception as e:
        print(f"Error in model evaluation: {e}")
        raise

"""# 6. MODEL SAVING FOR DEPLOYMENT"""

def save_model_for_deployment(model_path, class_names, output_dir):
    """
    Save model and metadata for deployment

    Args:
        model_path (str): Path to trained model
        class_names (list): List of class names
        output_dir (str): Output directory for deployment files
    """
    try:
        print("=" * 60)
        print("SAVING MODEL FOR DEPLOYMENT")
        print("=" * 60)

        os.makedirs(output_dir, exist_ok=True)

        # Load and save model in different formats
        model = tf.keras.models.load_model(model_path)

        # Save as SavedModel format (recommended for production)
        saved_model_path = os.path.join(output_dir, 'tree_species_model')
        model.save(saved_model_path)
        print(f"Model saved in SavedModel format: {saved_model_path}")

        # Save as H5 format (compatible with older versions)
        h5_model_path = os.path.join(output_dir, 'tree_species_model.h5')
        model.save(h5_model_path)
        print(f"Model saved in H5 format: {h5_model_path}")

        # Save model metadata
        metadata = {
            'model_name': 'Tree Species Classifier',
            'version': '1.0',
            'created_date': datetime.now().isoformat(),
            'num_classes': len(class_names),
            'class_names': class_names,
            'input_shape': [224, 224, 3],
            'preprocessing': {
                'rescale': '1./255',
                'target_size': [224, 224]
            }
        }

        metadata_path = os.path.join(output_dir, 'model_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        print(f"Model metadata saved: {metadata_path}")

        # Save class names separately
        class_names_path = os.path.join(output_dir, 'class_names.json')
        with open(class_names_path, 'w') as f:
            json.dump(class_names, f, indent=2)
        print(f"Class names saved: {class_names_path}")

        # Save preprocessing function
        preprocessing_code = '''
import cv2
import numpy as np

def preprocess_image(image_path, target_size=(224, 224)):
    """
    Preprocess image for model prediction

    Args:
        image_path (str): Path to image file
        target_size (tuple): Target image size

    Returns:
        np.array: Preprocessed image array
    """
    # Load image
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f"Could not load image: {image_path}")

    # Convert BGR to RGB
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Resize image
    img = cv2.resize(img, target_size)

    # Normalize pixel values
    img = img.astype(np.float32) / 255.0

    # Add batch dimension
    img = np.expand_dims(img, axis=0)

    return img
'''

        preprocessing_path = os.path.join(output_dir, 'preprocessing.py')
        with open(preprocessing_path, 'w') as f:
            f.write(preprocessing_code)
        print(f"Preprocessing code saved: {preprocessing_path}")

        print("Model deployment files saved successfully!")

    except Exception as e:
        print(f"Error saving model for deployment: {e}")
        raise

"""# 7. MODEL TESTING INTERFACE"""

def test_model_prediction(model_path, class_names_path, image_path):
    """
    Test model prediction on a single image

    Args:
        model_path (str): Path to saved model
        class_names_path (str): Path to class names JSON
        image_path (str): Path to test image

    Returns:
        dict: Prediction results
    """
    try:
        print("=" * 60)
        print("MODEL PREDICTION TEST")
        print("=" * 60)

        # Load model
        print(f"Loading model from: {model_path}")
        model = tf.keras.models.load_model(model_path)

        # Load class names
        with open(class_names_path, 'r') as f:
            class_names = json.load(f)

        # Check if image exists
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")

        print(f"Processing image: {image_path}")

        # Load and preprocess image
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"Could not load image: {image_path}")

        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_resized = cv2.resize(img_rgb, (224, 224))
        img_normalized = img_resized.astype(np.float32) / 255.0
        img_input = np.expand_dims(img_normalized, axis=0)

        # Make prediction
        predictions = model.predict(img_input, verbose=0)
        predicted_class_idx = np.argmax(predictions[0])
        predicted_probability = predictions[0][predicted_class_idx]
        predicted_class_name = class_names[predicted_class_idx]

        # Get top 5 predictions
        top_5_indices = np.argsort(predictions[0])[-5:][::-1]
        top_5_predictions = [
            {
                'class': class_names[i],
                'probability': float(predictions[0][i])
            }
            for i in top_5_indices
        ]

        print(f"\nPrediction Results:")
        print(f"Predicted Class: {predicted_class_name}")
        print(f"Confidence: {predicted_probability:.4f}")

        print(f"\nTop 5 Predictions:")
        for i, pred in enumerate(top_5_predictions, 1):
            print(f"{i}. {pred['class']}: {pred['probability']:.4f}")

        # Display image with prediction
        plt.figure(figsize=(10, 8))
        plt.imshow(img_rgb)
        plt.title(f"Predicted: {predicted_class_name}\nConfidence: {predicted_probability:.4f}")
        plt.axis('off')
        plt.show()

        return {
            'predicted_class': predicted_class_name,
            'confidence': float(predicted_probability),
            'top_5_predictions': top_5_predictions
        }

    except Exception as e:
        print(f"Error in model prediction: {e}")
        raise

def interactive_testing(model_path, class_names_path):
    """
    Interactive testing interface for model predictions

    Args:
        model_path (str): Path to saved model
        class_names_path (str): Path to class names JSON
    """
    try:
        print("=" * 60)
        print("INTERACTIVE MODEL TESTING")
        print("=" * 60)

        # Load model and class names
        print("Loading model and class names...")
        model = tf.keras.models.load_model(model_path)

        with open(class_names_path, 'r') as f:
            class_names = json.load(f)

        print(f"Model loaded successfully!")
        print(f"Number of classes: {len(class_names)}")
        print("Available classes:", ", ".join(class_names))

        while True:
            print("\n" + "="*50)
            print("Enter image path for prediction (or 'quit' to exit):")
            user_input = input("Image path: ").strip()

            if user_input.lower() in ['quit', 'exit', 'q']:
                print("Exiting interactive testing...")
                break

            if not user_input:
                print("Please enter a valid image path.")
                continue

            try:
                result = test_model_prediction(model_path, class_names_path, user_input)

                # Ask if user wants to continue
                continue_input = input("\nTest another image? (y/n): ").strip().lower()
                if continue_input in ['n', 'no']:
                    break

            except Exception as e:
                print(f"Error processing image: {e}")
                continue_input = input("Try another image? (y/n): ").strip().lower()
                if continue_input in ['n', 'no']:
                    break

    except Exception as e:
        print(f"Error in interactive testing: {e}")
        raise

"""# 8. MAIN EXECUTION PIPELINE"""

def main_training_pipeline(data_dir, output_base_dir):
    """
    Main training pipeline that orchestrates the entire process

    Args:
        data_dir (str): Path to original dataset
        output_base_dir (str): Base directory for all outputs

    Returns:
        dict: Pipeline results and paths
    """
    try:
        print("ðŸŒ³" * 20)
        print("TREE SPECIES CLASSIFICATION - TRAINING PIPELINE")
        print("ðŸŒ³" * 20)

        # Create output directories
        processed_data_dir = os.path.join(output_base_dir, 'processed_data')
        models_dir = os.path.join(output_base_dir, 'models')
        deployment_dir = os.path.join(output_base_dir, 'deployment')

        for dir_path in [processed_data_dir, models_dir, deployment_dir]:
            os.makedirs(dir_path, exist_ok=True)

        # Step 1: Dataset Exploration
        dataset_info = explore_dataset(data_dir)
        visualize_dataset_samples(dataset_info, data_dir)

        # Step 2: Data Preprocessing
        split_info = create_data_splits(dataset_info, processed_data_dir)
        train_generator, val_generator, class_names = create_data_generators(
            split_info['train_dir'],
            split_info['val_dir']
        )

        # Step 3: Model Building
        model = create_model(len(class_names))
        model_save_path = os.path.join(models_dir, 'best_tree_species_model.h5')
        callbacks = setup_callbacks(model_save_path)

        # Step 4: Model Training
        training_results = train_model(model, train_generator, val_generator, callbacks)
        plot_training_history(training_results['history'])

        # Step 5: Model Evaluation
        evaluation_results = evaluate_model(
            model_save_path,
            split_info['test_dir'],
            class_names
        )

        # Step 6: Save Model for Deployment
        save_model_for_deployment(model_save_path, class_names, deployment_dir)

        # Save training summary
        training_summary = {
            'dataset_info': dataset_info,
            'split_info': split_info['split_info'],
            'class_names': class_names,
            'model_architecture': 'EfficientNetB0 + Custom Layers',
            'training_results': {
                'final_train_accuracy': training_results['history']['accuracy'][-1],
                'final_val_accuracy': training_results['history']['val_accuracy'][-1],
                'final_train_loss': training_results['history']['loss'][-1],
                'final_val_loss': training_results['history']['val_loss'][-1]
            },
            'evaluation_results': {
                'test_accuracy': evaluation_results['test_accuracy'],
                'test_loss': evaluation_results['test_loss'],
                'test_top3_accuracy': evaluation_results['test_top3_accuracy']
            },
            'paths': {
                'model_path': model_save_path,
                'deployment_dir': deployment_dir,
                'class_names_path': os.path.join(deployment_dir, 'class_names.json')
            }
        }

        summary_path = os.path.join(output_base_dir, 'training_summary.json')
        with open(summary_path, 'w') as f:
            json.dump(training_summary, f, indent=2, default=str)

        print("=" * 60)
        print("TRAINING PIPELINE COMPLETED SUCCESSFULLY!")
        print("=" * 60)
        print(f"Final Results:")
        print(f"Test Accuracy: {evaluation_results['test_accuracy']:.4f}")
        print(f"Test Top-3 Accuracy: {evaluation_results['test_top3_accuracy']:.4f}")
        print(f"Model saved at: {model_save_path}")
        print(f"Deployment files saved at: {deployment_dir}")
        print(f"Training summary saved at: {summary_path}")

        return training_summary

    except Exception as e:
        print(f"Error in main training pipeline: {e}")
        raise

"""# 9. USAGE EXAMPLES"""

def run_complete_pipeline():
    """
    Example usage of the complete pipeline
    """
    # Configuration
    DATA_DIR = '/content/drive/MyDrive/Dataset/Tree_Species_Dataset'
    OUTPUT_BASE_DIR = '/content/drive/MyDrive/Tree_Species_ML_Project'

    try:
        # Run complete training pipeline
        results = main_training_pipeline(DATA_DIR, OUTPUT_BASE_DIR)

        # Test the trained model
        model_path = results['paths']['model_path']
        class_names_path = results['paths']['class_names_path']

        print("\n" + "="*60)
        print("TESTING THE TRAINED MODEL")
        print("="*60)

        # Example prediction (you can change this path)
        # test_image_path = "/path/to/your/test/image.jpg"
        # test_model_prediction(model_path, class_names_path, test_image_path)

        # Start interactive testing
        print("Starting interactive testing mode...")
        # interactive_testing(model_path, class_names_path)

    except Exception as e:
        print(f"Error running pipeline: {e}")
        raise

"""# 10. INDIVIDUAL FUNCTION USAGE EXAMPLES"""

"""
USAGE EXAMPLES:

# 1. Run complete pipeline
run_complete_pipeline()

# 2. Use individual functions

# Dataset exploration
dataset_info = explore_dataset('/path/to/dataset')
visualize_dataset_samples(dataset_info, '/path/to/dataset')

# Data preprocessing
split_info = create_data_splits(dataset_info, '/path/to/output')
train_gen, val_gen, classes = create_data_generators(
    split_info['train_dir'],
    split_info['val_dir']
)

# Model training
model = create_model(len(classes))
callbacks = setup_callbacks('/path/to/save/model.h5')
history = train_model(model, train_gen, val_gen, callbacks)

# Model evaluation
results = evaluate_model('/path/to/model.h5', '/path/to/test', classes)

# Save for deployment
save_model_for_deployment('/path/to/model.h5', classes, '/path/to/deployment')

# Test predictions
test_model_prediction('/path/to/model.h5', '/path/to/classes.json', '/path/to/image.jpg')

# Interactive testing
interactive_testing('/path/to/model.h5', '/path/to/classes.json')
"""

if __name__ == "__main__":
    # Run the complete pipeline
    run_complete_pipeline()







